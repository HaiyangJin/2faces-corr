---
title: "Two faces of holistic face processing -- analyses and results"
author: "[Haiyang Jin](https://haiyangjin.github.io/)"
date: "`r format(Sys.Date(), '%Y %b %d')`"
output: 
  html_document:
    code_folding: hide
    df_print: paged
    number_sections: true
    toc: true
    toc_depth: 4
    toc_float: true
---

```{=html}
<style>
pre {
overflow-x: auto;
}
pre code {
word-wrap: normal;
white-space: pre;
}
</style>
```

```{r global_options, echo = FALSE, include = FALSE}
options(width = 1500)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, 
                      include = TRUE, cache = FALSE, tidy = FALSE, 
                      size = "big", fig.width=8, fig.asp=0.7)
xaringanExtra::use_clipboard()
```

# Preparations
Load libraries and general settings:
```{r setup}
## load libraries
library(tidyverse)
library(lme4)
library(lmerTest)
library(optimx)
library(emmeans)
library(psych)
library(ggpubr)
library(here)
```

```{r}
emm_options(lmer.df = "asymptotic") # as pre-registered
             
two_colors <- c("#D55E00", "#56B4E9") # facilitation and interference
dark_colors <- c("#800D00", "#165F83", "gray45") # darker (facilitation, interference, null)
subt_shape <- 20 # diamond
regr_shape <- 18 # round

save_figure <- FALSE

# APA theme for figures
theme_set(papaja::theme_apa(base_size = 12, base_family = "Helvetica", box = FALSE))
theme_update(strip.placement = "outside")
```

## Load data 
```{r}
# To run the code in this chunk, you need to put all raw data files into data/.

# # read all raw data, remove subjid and re-save as a new file
# df_raw_tmp <- list.files("data", pattern = "*.csv", full.names = TRUE) %>%
#   map_dfr(read_csv, show_col_types = FALSE, .id="Subject") %>% # overwrite Subject ID from Prolific
#   mutate(Subject = sprintf("subj%03d", as.integer(Subject))) # add new Subject
#
# write_rds(df_raw_tmp, here("data", "2faces_pro_raw480.rds"))
# write_csv(df_raw_tmp, here("data", "2faces_pro_raw480.csv"))

# connections between prolific subject ID and ID in this study
# df_subjects <- list.files("data", pattern = "*.csv", full.names = TRUE) %>%
#   map_dfr(read_csv, show_col_types = FALSE, .id="SubjectThis") %>% # overwrite Subject ID from Prolific
#   mutate(SubjectThis = sprintf("subj%03d", as.integer(SubjectThis))) %>%  # add new Subject
#   select(ProlificID = Subject, Subject = SubjectThis) %>% 
#   distinct()
# 
# write_rds(df_subjects, here("data", "2faces_pro_subjectID.rds"))
# write_csv(df_subjects, here("data", "2faces_pro_subjectID.csv"))
```

The structure of the raw data `df_raw`:
```{r}
# load data
df_raw <- readRDS(here("data", "2faces_pro_raw480.rds")) %>% 
  filter(trial_frame=="test_face",
         Section=="main") %>% # exclude practice trials
  select(Subject, CBcode, Task_name:SameDifferent, 
         Correct_ans_posi, Correct_response, response, 
         Correct, RT, StimGroup, StudyFace, TestFace) %>% 
  transmute(Subject = as_factor(Subject),
            Task = as_factor(Task_name), # Task_order
            Trial_num,
            PW = as_factor(PW), 
            Feature = as_factor(Feature),
            Cue = as_factor(Cue),
            Congruency = as_factor(str_sub(Congruency, 1, 3)),
            Alignment = as_factor(str_sub(Alignment, 1, 3)),
            SD = as_factor(str_sub(SameDifferent, 1, 4)),
            SD = fct_relevel(SD, "same", "diff"),
            CorrectAnswer = Correct_response, 
            Response = response,
            Correct,
            RT,
            StimGroup = if_else(Task_name=="PW", 
                                str_remove(basename(StudyFace),".png"), 
                                StimGroup),
            StudyFace, 
            TestFace) 

str(df_raw)
```

## Tidy data

The information on inclusion and exclusion criteria can be found in [the online pre-registration](https://osf.io/5sjxa){target="_blank"}.

### Exclude participants

We will first exclude participants who had 10% or more trials in any of the three tasks with either very fast or very slow responses (<200ms or >5000ms). 

```{r}
df_ex_subj <- df_raw %>% 
  mutate(isout = RT < 200 | RT > 5000) %>%  # identify outlier trials
  group_by(Subject, Task) %>% 
  summarize(count_all = n(),
            count_out = sum(isout),
            .groups = "drop") %>% 
  mutate(ratio = count_out/count_all) %>% 
  filter(ratio >= .1) # who had 10% or more trials 

(subjlist_ex <- unique(df_ex_subj$Subject))
```

In summary, `r length(subjlist_ex)` participants were excluded, and therefore, there are `r nlevels(df_ex_subj$Subject)-length(subjlist_ex)` remaining (valid) participants.

### Exclude trials

Second, we exclude outlier trials in the remaining participants. We calculate the standard deviations (SDs) of response times (RTs) for each condition and each participant in each task separately (e.g., for part-whole task, such a condition would be a whole-face condition with a specific target feature such as the eyes. For the standard composite task, such a condition would be same-aligned trials). Trials with responses made <200ms or > 3SDs of the condition will be excluded. 


On average, the percentages of trials removed for each task:
```{r}
df_raw <- df_raw %>% 
  filter(!Subject %in% subjlist_ex) %>% # exclude outlier subjects
  group_by(Subject, Task, PW, Feature, Cue, Congruency, Alignment, SD) %>% 
  summarize(Trial_num, CorrectAnswer, Response, Correct, RT, 
            StimGroup, StudyFace, TestFace,
            Z_rt = scale(RT), # calculate Z value
            .groups = "drop") %>% 
  mutate(isout = Z_rt < -3 | Z_rt > 3 | RT < 200) 

df_raw %>% 
  group_by(Subject, Task) %>% 
  summarize(count = n(),
            count_out = sum(isout),
            .groups = "drop") %>% 
  mutate(ratio = count_out/count) %>% 
  group_by(Task) %>% 
  summarize(count = mean(count),
            avg_outlier_N = mean(count_out),
            `avg_outlier_ratio (%)` = mean(ratio)*100) 
```

## Save data for each task separately

The structure of the clean data (`df_tidy`):
```{r}
df_tidy <- df_raw %>% 
  filter(!isout) %>% 
  select(-c(Z_rt, isout))

# saveRDS(df_tidy, file=here("data", "df_tidy.rds"))

str(df_tidy)
```


```{r}
# custom function to set contrasts for factors
set_sdif <- function(.data, colstr, n=2){
  # .data dataframe
  # colstr the string of the column name
  
  contrasts(.data[[colstr]]) <- MASS::contr.sdif(n)
  
  return(.data)
}
```

### Part-whole task
The structure of the clean data for part-whole task (`df_pw`):
```{r}
df_pw <- df_tidy %>% 
  filter(Task == "PW",
         Feature != "nose") %>% # do not include Nose trials in GLMM
  select(Subject, PW, Feature, Correct, RT, StimGroup, StudyFace, TestFace) %>% 
  mutate(PW = fct_relevel(PW, "whole", "part"),
         Feature = fct_drop(Feature),
         PW_C = if_else(PW=="whole", -.5, if_else(PW=="part", .5, NaN)),
         Feature_C = if_else(Feature=="mouth", -.5, 
                             if_else(Feature=="eyes", .5, NaN)),
         PW_Feature = PW_C * Feature_C) %>% 
  set_sdif("PW") %>% 
  set_sdif("Feature")

# saveRDS(df_pw, file=here("jubail", "df_pw.rds"))

str(df_pw)
```

### Standard composite face task
The structure of the clean data for standard composite face task (`df_scf`):
```{r}
df_scf <- df_tidy %>% 
  filter(Task == "SCF",
         SD == "same") %>% # only use trials when the top is the same
  select(Subject, Alignment, Correct, RT, Trial_num, StimGroup) %>% 
  mutate(Alignment = fct_drop(Alignment),
         Ali_C = if_else(Alignment=="ali", -.5, 
                         if_else(Alignment=="mis", .5, NaN))) %>% 
  set_sdif("Alignment")

# saveRDS(df_scf, file=here("jubail", "df_scf.rds"))

str(df_scf)
```

### Complete composite face task
The structure of the clean data for complete composite face task (`df_ccf`):
```{r}
# including isolated condition
df_ccf_iso <- df_tidy %>% 
  filter(Task == "CCF") %>% # only use trials when the top is the same
  mutate(isSame = if_else( # whether participants responded "same" (signal)
    ((SD=="same")&Correct) | ((SD=="diff")&!Correct), 1,
    if_else(((SD=="same")&!Correct) | ((SD=="diff")&Correct), 0, NaN))) %>% 
  select(Subject, Cue, Congruency, Alignment, SD, Correct, 
         isSame, RT, Trial_num, StimGroup) 

# df_ccf for composite effect
df_ccf <- df_ccf_iso %>% 
  filter(Alignment != "iso") %>% 
  mutate(Alignment = fct_drop(Alignment),
         Congruency = fct_drop(Congruency)) %>% 
  set_sdif("Cue") %>% 
  set_sdif("Congruency") %>% 
  set_sdif("Alignment") %>% 
  set_sdif("SD") %>% 
  mutate(Con_C = if_else(Congruency=="con", -.5,
                         if_else(Congruency=="inc", .5, NaN)),
         Ali_C = if_else(Alignment=="ali", -.5,
                         if_else(Alignment=="mis", .5, NaN)),
         SD_C = if_else(SD=="same", -.5, if_else(SD=="diff", .5, NaN)),
         Con_Ali = Con_C * Ali_C,
         Con_SD = Con_C * SD_C,
         Ali_SD = Ali_C * SD_C,
         Con_Ali_SD = Con_Ali * SD_C)

# saveRDS(df_ccf, file=here("jubail", "df_ccf.rds"))

str(df_ccf)
```

The structure of the clean data for analysis involving isolated conditions for calculating facilitation and interference (`df_fi`):
```{r}
# facilitation and interference

# df for facilitation and interference
df_fi <- df_ccf_iso %>% 
  filter(Alignment != "mis") %>% 
  select(-Alignment) %>% 
  set_sdif("Cue") %>% 
  set_sdif("Congruency", 3) %>% 
  set_sdif("SD") %>% 
  mutate(ConInc = if_else(Congruency=="con", -2/3,
                         if_else(Congruency %in% c("inc", "iso"), 1/3, NaN)),
         IncIso = if_else(Congruency=="iso", 2/3,
                         if_else(Congruency %in% c("inc", "con"), -1/3, NaN)),
         SD_C = if_else(SD=="same", -.5, if_else(SD=="diff", .5, NaN)),
         ConInc_SD = ConInc * SD_C,
         IncIso_SD = IncIso * SD_C)

# saveRDS(df_fi, file=here("jubail", "df_fi.rds"))

str(df_fi)
```


```{r child=c("2faces_1GLMM.Rmd", "2faces_2Corr.Rmd", "2faces_3SessInfo.Rmd")}
```

