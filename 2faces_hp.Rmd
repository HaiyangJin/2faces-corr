---
title: "Two faces of holistic face processing -- analyses and results"
author: "[Haiyang Jin](https://haiyangjin.github.io/)"
date: "`r format(Sys.Date(), '%Y %b %d')`"
output: 
  html_document:
    code_folding: hide
    number_sections: true
    toc: true
    toc_depth: 4
    toc_float: true
---

```{=html}
<style>
pre {
overflow-x: auto;
}
pre code {
word-wrap: normal;
white-space: pre;
}
</style>
```

```{r global_options, echo = FALSE, include = FALSE}
options(width = 1500)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, 
                      include = TRUE, cache = FALSE, tidy = FALSE, 
                      size = "big", fig.width=8, fig.asp=0.7)
xaringanExtra::use_clipboard()
```

# Preparations
```{r setup}
## load libraries
library(tidyverse)
library(lme4)
library(lmerTest)
library(optimx)
library(emmeans)
library(psych)
library(ggpubr)
```

```{r}
two_colors <- c("#D55E00", "#56B4E9")

# APA theme for figures
theme_set(papaja::theme_apa(base_size = 12, base_family = "Helvetica", box = FALSE))
theme_update(strip.placement = "outside")
```

## Load data 
```{r read the data file}
# list filenames
prolific_list <- list.files(file.path("data", "pilot", "prolific"), 
                            pattern = "*.csv", full.names = TRUE)
testable1_list <- list.files(file.path("data", "pilot", "testable1"), 
                             pattern = "*.csv", full.names = TRUE)

# load data
df_raw_p <- map_dfr(prolific_list, read_csv, show_col_types = FALSE, .id="id") 
df_raw_t1 <- map_dfr(testable1_list, read_csv, show_col_types = FALSE, .id="id") 

# combine data from the two experiments
df_raw_p_tmp <- df_raw_p %>% 
  filter(trial_frame=="test_face") %>% 
  select(Exp_name, Subject, CBcode, isPavlovia, Task_name:SameDifferent, 
         Correct_ans_posi, Correct_response, response, Correct, RT, StimGroup, StudyFace, TestFace) %>% 
  mutate(platform = "Prolific")

df_raw_t1_tmp <- df_raw_t1 %>% 
  filter(trial_frame=="test_face") %>% 
  select(Exp_name, Subject, CBcode, isPavlovia, Task_name:SameDifferent, 
         Correct_ans_posi, Correct_response, response, Correct, RT, StimGroup, StudyFace, TestFace) %>% 
  mutate(platform = "Testable1")

df_raw <- bind_rows(df_raw_p_tmp, df_raw_t1_tmp) %>% 
  filter(Section=="main") %>% # exclude practice trials
  mutate(Exp_name = as_factor(Exp_name),
         Subject = paste0("subj",as.numeric(as_factor(Subject))),
         Subject = as_factor(Subject),
         Task = as_factor(Task_name),
         PW = as_factor(PW), 
         Feature = as_factor(Feature),
         Cue = as_factor(Cue),
         Congruency = as_factor(str_sub(Congruency, 1, 3)),
         Alignment = as_factor(str_sub(Alignment, 1, 3)),
         SD = as_factor(str_sub(SameDifferent, 1, 3)),
         SD = fct_relevel(SD, "sam", "dif"),
         Correct_ans_posi = as_factor(Correct_ans_posi),
         StimGroup = if_else(Task_name=="PW", str_remove(basename(StudyFace),".png"), StimGroup),
         platform = as_factor(platform)) %>% 
  select(-c(Section, SameDifferent))

head(df_raw)
```

## Tidy data

Remove outlier participants and outlier trials. 
```{r}
df_tidy <- df_raw 
```


```{r}
# custom function to set contrasts for factors
set_sdif <- function(.data, colstr, n=2){
  # .data dataframe
  # colstr the string of the column name
  
  contrasts(.data[[colstr]]) <- MASS::contr.sdif(n)
  
  return(.data)
}
```


### Part-whole task

```{r}
df_pw <- df_tidy %>% 
  filter(Task_name == "PW",
         Feature != "nose") %>% # do not include Nose trials in GLMM
  select(Subject, PW, Feature, Correct, RT, StimGroup) %>% 
  mutate(PW = fct_relevel(PW, "whole", "part"),
         Feature = fct_drop(Feature),
         PW_C = if_else(PW=="whole", -.5, if_else(PW=="part", .5, NaN)),
         Feature_C = if_else(Feature=="mouth", -.5, 
                             if_else(Feature=="eyes", .5, NaN)),
         PW_Feature = PW_C * Feature_C) %>% 
  set_sdif("PW") %>% 
  set_sdif("Feature")

# saveRDS(df_pw, file=file.path("jubail", "df_pw.rds"))

str(df_pw)
```

### Standard composite face task

```{r}
df_scf <- df_tidy %>% 
  filter(Task_name == "SCF",
         SD == "sam") %>% # only use trials when the top is the same
  select(Subject, Alignment, Correct, RT, StimGroup) %>% 
  mutate(Alignment = fct_drop(Alignment),
         Ali_C = if_else(Alignment=="ali", -.5, 
                         if_else(Alignment=="mis", .5, NaN))) %>% 
  set_sdif("Alignment")

# saveRDS(df_scf, file=file.path("jubail", "df_scf.rds"))

str(df_scf)
```

### Complete composite face task

```{r}
# including isolated condition
df_ccf_iso <- df_tidy %>% 
  filter(Task_name == "CCF") %>% # only use trials when the top is the same
  mutate(isSame = if_else( # whether participants responded "same" (signal)
    ((SD=="sam")&Correct) | ((SD=="dif")&!Correct), 1,
    if_else(((SD=="sam")&!Correct) | ((SD=="dif")&Correct), 0, NaN))) %>% 
  select(Subject, Cue, Congruency, Alignment, SD, Correct, isSame, RT, StimGroup) 

df_ccf <- df_ccf_iso %>% 
  filter(Alignment != "iso") %>% 
  mutate(Alignment = fct_drop(Alignment),
         Congruency = fct_drop(Congruency)) %>% 
  set_sdif("Cue") %>% 
  set_sdif("Congruency") %>% 
  set_sdif("Alignment") %>% 
  set_sdif("SD")

# saveRDS(df_ccf, file=file.path("jubail", "df_ccf.rds"))

str(df_ccf)
```

# Holistic processing effects

Linear mixed-effects models are used to examine the holistic processing effects in the part-whole, standard composite face task, and complete composite face task.

## Steps to obtain the optimal model

1. If the maximal model did not converge, correlations between random effects were removed, making the zero-correlation-parameter (ZCP) model. 
2. Principal component analysis implemented with `rePCA()` function was then used to identify random effects that explained less than 0.1% of the total variances; they were removed from the ZCP model to make the reduced model. 
3. The extended model was built by adding back the correlations between random effects in the reduced model. 
4. If the extended model did not converge, the random effects that explained less than 1% of total variances were identified by `rePCA()` and removed to make the updated extended model; this step was iterated until an extended model converged. 
5. The converged extended model was then compared to the reduced model via `anova()` function and the model that explained the data better (with smaller Bayesian Information Criterion) was used as the optimal model. 
6. All follow-up analyses were performed on the optimal model. 

## Part-whole task

### Accuracy 

#### Maximal model

```{r}
thisfile <- file.path("jubail", "lmm_pw_acc_max.rds")

if (file.exists(thisfile)) {
  
  lmm_pw_acc_max <- readRDS(thisfile)
  
} else {
  lmm_pw_acc_max <- 
    glmer(Correct ~ PW * Feature + 
            (PW * Feature | Subject) +
            (PW * Feature | StimGroup),
          df_pw,
          family = binomial(link = "logit"),
          control = glmerControl(optimizer = "optimx", 
                                 optCtrl = list(method = "nlminb", 
                                                starttests = FALSE, 
                                                kkt = FALSE)))
  saveRDS(lmm_pw_acc_max, thisfile)
}

summary(lmm_pw_acc_max)
```

#### Zero-correlation-parameter model

```{r}
thisfile <- file.path("jubail", "lmm_pw_acc_zcp.rds")

if (file.exists(thisfile)) {
  
  lmm_pw_acc_zcp <- readRDS(thisfile)
  
} else {
  lmm_pw_acc_zcp <- 
    glmer(Correct ~ PW * Feature + 
            (PW_C + Feature_C + PW_Feature || Subject) +
            (PW_C + Feature_C + PW_Feature || StimGroup),
          df_pw,
          family = binomial(link = "logit"),
          control = glmerControl(optimizer = "optimx", 
                                 optCtrl = list(method = "nlminb", 
                                                starttests = FALSE, 
                                                kkt = FALSE)))
  saveRDS(lmm_pw_acc_zcp, thisfile)
}

summary(lmm_pw_acc_zcp)
```

```{r}
summary(rePCA(lmm_pw_acc_zcp))
```

#### Reduced model

```{r}
thisfile <- file.path("jubail", "lmm_pw_acc_.rds")

if (file.exists(thisfile)) {
  
  lmm_pw_acc_rdc <- readRDS(thisfile)
  
} else {
  lmm_pw_acc_rdc <- 
    glmer(Correct ~ PW * Feature + 
            (PW_C + Feature_C || Subject) +
            (PW_C + Feature_C + PW_Feature || StimGroup),
          df_pw,
          family = binomial(link = "logit"),
          control = glmerControl(optimizer = "optimx", 
                                 optCtrl = list(method = "nlminb", 
                                                starttests = FALSE, 
                                                kkt = FALSE)))
  saveRDS(lmm_pw_acc_rdc, thisfile)
}

summary(lmm_pw_acc_rdc)
```

#### Extended model

```{r}
thisfile <- file.path("jubail", "lmm_pw_acc_etd.rds")

if (file.exists(thisfile)) {
  
  lmm_pw_acc_etd <- readRDS(thisfile)
  
} else {
  lmm_pw_acc_etd <- 
    glmer(Correct ~ PW * Feature + 
            (PW_C + Feature_C | Subject) +
            (PW_C + Feature_C + PW_Feature | StimGroup),
          df_pw,
          family = binomial(link = "logit"),
          control = glmerControl(optimizer = "optimx", 
                                 optCtrl = list(method = "nlminb", 
                                                starttests = FALSE, 
                                                kkt = FALSE)))
  saveRDS(lmm_pw_acc_etd, thisfile)
}

summary(lmm_pw_acc_etd)
```

```{r}
summary(rePCA(lmm_pw_acc_etd))
```

```{r}
thisfile <- file.path("jubail", "lmm_pw_acc_etd2.rds")

if (file.exists(thisfile)) {
  
  lmm_pw_acc_etd2 <- readRDS(thisfile)
  
} else {
  lmm_pw_acc_etd2 <- 
    glmer(Correct ~ PW * Feature + 
            (PW_C | Subject) +
            (0 + Feature_C + PW_Feature | StimGroup),
          df_pw,
          family = binomial(link = "logit"),
          control = glmerControl(optimizer = "optimx", 
                                 optCtrl = list(method = "nlminb", 
                                                starttests = FALSE, 
                                                kkt = FALSE)))
  saveRDS(lmm_pw_acc_etd2, thisfile)
}

summary(lmm_pw_acc_etd2)
```

#### Optimal model

```{r}
anova(lmm_pw_acc_rdc, lmm_pw_acc_etd2)
```

```{r}
lmm_pw_acc_opt <- lmm_pw_acc_etd
```

#### Effects of interest
```{r}
emm_pw_acc <- emmeans(lmm_pw_acc_opt, ~ PW + Feature, type = "response")
emm_pw_acc
```

```{r}
contrast(emmeans(lmm_pw_acc_opt, ~ PW), "revpairwise")
```

```{r}
contrast(emmeans(lmm_pw_acc_opt, ~ PW), "revpairwise", type="response")
```

```{r}
contrast(emmeans(lmm_pw_acc_opt, ~ PW | Feature), "pairwise")
```


```{r}
emmip(lmm_pw_acc_opt, ~ PW | Feature, CIs = TRUE, type = "response") 
```


### Correct response times

#### Maximal model

```{r}
thisfile <- file.path("jubail", "lmm_pw_rt_max.rds")

if (file.exists(thisfile)) {
  
  lmm_pw_rt_max <- readRDS(thisfile)
  
} else {
  lmm_pw_rt_max <- 
    lmer(log(RT) ~ PW * Feature + 
           (PW * Feature | Subject) +
           (PW * Feature | StimGroup),
         filter(df_pw, Correct),
         control = lmerControl(optimizer = "optimx", 
                               optCtrl = list(method = "nlminb", 
                                              starttests = FALSE, 
                                              kkt = FALSE)))
  saveRDS(lmm_pw_rt_max, thisfile)
}

summary(lmm_pw_rt_max)
```

#### Zero-correlation-parameter model

```{r}
thisfile <- file.path("jubail", "lmm_pw_rt_zcp.rds")

if (file.exists(thisfile)) {
  
  lmm_pw_rt_zcp <- readRDS(thisfile)
  
} else {
  lmm_pw_rt_zcp <- 
    lmer(log(RT) ~ PW * Feature + 
           (PW_C + Feature_C + PW_Feature || Subject) +
           (PW_C + Feature_C + PW_Feature || StimGroup),
         filter(df_pw, Correct),
         control = lmerControl(optimizer = "optimx", 
                               optCtrl = list(method = "nlminb", 
                                              starttests = FALSE, 
                                              kkt = FALSE)))
  saveRDS(lmm_pw_rt_zcp, thisfile)
}

summary(lmm_pw_rt_zcp)
```

```{r}
summary(rePCA(lmm_pw_rt_zcp))
```

#### Reduced model

```{r}
thisfile <- file.path("jubail", "lmm_pw_rt_rdc.rds")

if (file.exists(thisfile)) {
  
  lmm_pw_rt_rdc <- readRDS(thisfile)
  
} else {
  lmm_pw_rt_rdc <- 
    lmer(log(RT) ~ PW * Feature + 
           (PW_C + Feature_C || Subject) +
           (PW_C + Feature_C || StimGroup),
         filter(df_pw, Correct),
         control = lmerControl(optimizer = "optimx", 
                               optCtrl = list(method = "nlminb", 
                                              starttests = FALSE, 
                                              kkt = FALSE)))
  saveRDS(lmm_pw_rt_rdc, thisfile)
}

summary(lmm_pw_rt_rdc)
```

#### Extended model

```{r}
thisfile <- file.path("jubail", "lmm_pw_rt_etd.rds")

if (file.exists(thisfile)) {
  
  lmm_pw_rt_etd <- readRDS(thisfile)
  
} else {
  lmm_pw_rt_etd <- 
    lmer(log(RT) ~ PW * Feature + 
           (PW_C + Feature_C | Subject) +
           (PW_C + Feature_C | StimGroup),
         filter(df_pw, Correct),
         control = lmerControl(optimizer = "optimx", 
                               optCtrl = list(method = "nlminb", 
                                              starttests = FALSE, 
                                              kkt = FALSE)))
  saveRDS(lmm_pw_rt_etd, thisfile)
}

summary(lmm_pw_rt_etd)
```

```{r}
summary(rePCA(lmm_pw_rt_etd))
```

```{r}
thisfile <- file.path("jubail", "lmm_pw_rt_etd2.rds")

if (file.exists(thisfile)) {
  
  lmm_pw_rt_etd2 <- readRDS(thisfile)
  
} else {
  lmm_pw_rt_etd2 <- 
    lmer(log(RT) ~ PW * Feature + 
           (PW_C | Subject) +
           (0 + PW_C + Feature_C | StimGroup),
         filter(df_pw, Correct),
         control = lmerControl(optimizer = "optimx", 
                               optCtrl = list(method = "nlminb", 
                                              starttests = FALSE, 
                                              kkt = FALSE)))
  saveRDS(lmm_pw_rt_etd2, thisfile)
}

summary(lmm_pw_rt_etd2)
```

#### Optimal model

```{r}
anova(lmm_pw_rt_rdc, lmm_pw_rt_etd2)
```

```{r}
anova(lmm_pw_rt_rdc, lmm_pw_rt_etd2, refit=FALSE)
```

```{r}
lmm_pw_rt_opt <- lmm_pw_rt_etd2
```


#### Effects of interest
```{r}
emm_pw_rt <- emmeans(lmm_pw_rt_opt, ~ PW + Feature)
emm_pw_rt
```

```{r}
contrast(emmeans(lmm_pw_rt_opt, ~ PW), "pairwise")
```

```{r}
contrast(emmeans(lmm_pw_rt_opt, ~ PW), "pairwise", type = "response")
```

```{r}
contrast(emmeans(lmm_pw_rt_opt, ~ PW | Feature), "pairwise")
```


```{r}
emmip(lmm_pw_rt_opt, ~ PW | Feature, CIs = TRUE, type = "response") 
```


## Standard composite face task

### Accuracy 


#### Maximal model
```{r}
thisfile <- file.path("jubail", "lmm_scf_acc_max.rds")

if (file.exists(thisfile)) {
  
  lmm_scf_acc_max <- readRDS(thisfile)
  
} else {
  lmm_scf_acc_max <- glmer(Correct ~ Alignment + 
                             (Alignment | Subject) +
                             (Alignment | StimGroup),
                           df_scf,
                           family = binomial(link = "logit"),
                           control = glmerControl(optimizer = "optimx", 
                                                  optCtrl = list(method = "nlminb", 
                                                                 starttests = FALSE, 
                                                                 kkt = FALSE)))
  saveRDS(lmm_scf_acc_max, thisfile)
}

summary(lmm_scf_acc_max)
```

#### Zero-correlation-parameter model

```{r}
thisfile <- file.path("jubail", "lmm_scf_acc_zcp.rds")

if (file.exists(thisfile)) {
  
  lmm_scf_acc_zcp <- readRDS(thisfile)
  
} else {
  lmm_scf_acc_zcp <- glmer(Correct ~ Alignment + 
                             (Ali_C | Subject) +
                             (Ali_C | StimGroup),
                           df_scf,
                           family = binomial(link = "logit"),
                           control = glmerControl(optimizer = "optimx", 
                                                  optCtrl = list(method = "nlminb", 
                                                                 starttests = FALSE, 
                                                                 kkt = FALSE)))
  saveRDS(lmm_scf_acc_zcp, thisfile)
}

summary(lmm_scf_acc_zcp)
```

#### Optimal model

```{r}
lmm_scf_acc_opt <- lmm_scf_acc_max
```

#### Effects of interest
```{r}
emm_scf_acc <- emmeans(lmm_scf_acc_opt, ~ Alignment, type="response")
emm_scf_acc
```

```{r}
contrast(emmeans(lmm_scf_acc_opt, ~ Alignment), "pairwise")
```


```{r}
emmip(lmm_scf_acc_opt, ~ Alignment, CIs = TRUE, type = "response") 
```



### Correct response times

#### Maximal model
```{r}
thisfile <- file.path("jubail", "lmm_scf_rt_max.rds")

if (file.exists(thisfile)) {
  
  lmm_scf_rt_max <- readRDS(thisfile)
  
} else {
  lmm_scf_rt_max <- lmer(log(RT) ~ Alignment + 
                           (Alignment | Subject) +
                           (Alignment | StimGroup),
                         filter(df_scf, Correct),
                         control = lmerControl(optimizer = "optimx", 
                                               optCtrl = list(method = "nlminb", 
                                                              starttests = FALSE, 
                                                              kkt = FALSE)))
  saveRDS(lmm_scf_rt_max, thisfile)
}

summary(lmm_scf_rt_max)
```

#### Optimal model
```{r}
lmm_scf_rt_opt <- lmm_scf_rt_max
```


#### Effects of interest
```{r}
emm_scf_rt <- emmeans(lmm_scf_rt_opt, ~ Alignment, type = "response")
emm_scf_rt
```

```{r}
contrast(emmeans(lmm_scf_rt_opt, ~ Alignment), "pairwise")
```

```{r}
contrast(emmeans(lmm_scf_rt_opt, ~ Alignment), "pairwise", type = "response")
```


```{r}
emmip(lmm_scf_rt_opt, ~ Alignment, CIs = TRUE, type = "response") 
```


## Complete composite face task

### Sensitivity d'

#### Maximal model
```{r}
thisfile <- file.path("jubail", "lmm_ccf_d_max.rds")

if (file.exists(thisfile)) {
  
  lmm_ccf_d_max <- readRDS(thisfile)
  
} else {
  lmm_ccf_d_max <- glmer(isSame ~ Congruency * Alignment * SD + Cue +
                           (Congruency * Alignment * SD | Subject) +
                           (Congruency * Alignment * SD | StimGroup),
                         df_ccf,
                         family = binomial(link = "probit"),
                         control = glmerControl(optimizer = "optimx", 
                                                optCtrl = list(method = "nlminb", 
                                                               starttests = FALSE, 
                                                               kkt = FALSE)))
  saveRDS(lmm_ccf_d_max, thisfile)
}

summary(lmm_ccf_d_max)
```

#### Optimal model
```{r}
lmm_ccf_d_opt <- lmm_ccf_d_max
```

#### Effects of interest
```{r}
(emm_ccf_probit <- emmeans(lmm_ccf_d_opt, ~ Congruency + Alignment + SD, type = "response"))
```


```{r}
emm_ccf_d <- contrast(emm_ccf_probit, "pairwise", simple="SD")
emm_ccf_d[1:4]
```

```{r}
cong_emm <- contrast(emm_ccf_probit, interaction="pairwise", by="Alignment")
cong_emm[2]
```

```{r}
contrast(emm_ccf_probit, interaction="pairwise")
```


```{r}
emmip(emm_ccf_d, Congruency ~ Alignment, CIs = TRUE)
```


### Correct response times

#### Maximal model
```{r}
thisfile <- file.path("jubail", "lmm_ccf_rt_max.rds")

if (file.exists(thisfile)) {
  
  lmm_ccf_rt_max <- readRDS(thisfile)
  
} else {
  lmm_ccf_rt_max <- lmer(log(RT) ~ Congruency * Alignment + 
                           (Congruency * Alignment | Subject) +
                           (Congruency * Alignment | StimGroup),
                         filter(df_ccf, Correct),
                         control = lmerControl(optimizer = "optimx", 
                                               optCtrl = list(method = "nlminb", 
                                                              starttests = FALSE, 
                                                              kkt = FALSE)))
  saveRDS(lmm_ccf_rt_max, thisfile)
}

summary(lmm_ccf_rt_max)
```

#### Optimal model
```{r}
lmm_ccf_rt_opt <- lmm_ccf_rt_max
```

#### Effects of interest
```{r}
thisfile <- file.path("jubail", "emm_ccf_rt.rds")

if (file.exists(thisfile)) {
  
  emm_ccf_rt <- readRDS(thisfile)
  
} else {
  emm_ccf_rt <- emmeans(lmm_ccf_rt_opt, ~ Congruency + Alignment, type = "response",
                        lmerTest.limit = 6400,
                        pbkrtest.limit = 6400)
  
  saveRDS(emm_ccf_rt, thisfile)
}

emm_ccf_rt
```

```{r}
contrast(emm_ccf_rt, interaction="pairwise")
```

```{r}
contrast(emm_ccf_rt, interaction="pairwise", type = "response")
```


```{r}
emmip(emm_ccf_rt, Congruency ~ Alignment, CIs = TRUE, type = "response") 
```


# Relationships among effects

## Calculate holistic processing effects

```{r}
# custom function to use linear models to apply the regression method
cal_reg <- function(.data, formula, outvar){
  
  # .data: the input dataframe
  # formula: used in lm()
  # outvar: the column name for the regression effect (residuals) [new column]
  
  # perform linear regression
  lm_tmp <- lm(formula, .data)
  
  # save the residuals
  return(mutate(.data, {{outvar}} := residuals(lm_tmp))) # outvar is a variable
  # return(mutate(.data, "{outvar}" := residuals(lm_tmp))) # outvar is a string
}
```


### Part-whole task

```{r}
pwe_acc <- df_pw %>% 
  group_by(Subject, PW) %>% 
  summarize(acc = mean(Correct),
            count = n(),
            acc_cor = if_else(acc==1, (2*count-1)/(2*count), acc),
            logit = qlogis(acc_cor),
            .groups = "drop") %>% 
  pivot_wider(Subject, names_from = PW, values_from = logit) %>% 
  mutate(pwe_subt = whole - part) %>% # subtraction
  cal_reg(whole ~ part, pwe_regr) # regression

pwe_acc
```


```{r}
pwe_rt <- df_pw %>% 
  filter(Correct) %>% 
  group_by(Subject, PW) %>% 
  summarize(rt = mean(RT),
            logrt = log(rt),
            .groups = "drop") %>% 
  pivot_wider(Subject, names_from = PW, values_from = logrt) %>% 
  mutate(pwe_subt = whole - part) %>% # subtraction
  cal_reg(whole ~ part, pwe_regr) # regression

pwe_rt
```

### Standard composite face task

```{r}
scfe_acc <- df_scf %>% 
  group_by(Subject, Alignment) %>% 
  summarize(acc = mean(Correct),
            count = n(),
            acc_cor = if_else(acc==1, (2*count-1)/(2*count), acc),
            logit = qlogis(acc_cor),
            .groups = "drop") %>% 
  pivot_wider(Subject, names_from = Alignment, values_from = logit) %>% 
  mutate(scfe_subt = ali - mis) %>% # subtraction
  cal_reg(ali ~ mis, scfe_regr) # regression

scfe_acc
```


```{r}
scfe_rt <- df_scf %>% 
  filter(Correct) %>% 
  group_by(Subject, Alignment) %>% 
  summarize(logrt = log(mean(RT)),
            .groups = "drop") %>% 
  pivot_wider(Subject, names_from = Alignment, values_from = logrt) %>% 
  mutate(scfe_subt = ali - mis) %>% # subtraction
  cal_reg(ali ~ mis, scfe_regr) # regression
  
scfe_rt
```

### Complete compositie face task

```{r}
ccfe_d <- df_ccf_iso %>% 
  group_by(Subject, Congruency, Alignment, SD) %>% 
  summarize(count = n(),
            same_adjust = (sum(isSame)+0.5)/(count+1), # Snodgrass & Corwin (1988)
            .groups = "drop") %>% 
  mutate(z = qnorm(same_adjust)) %>% 
  select(-same_adjust) %>% 
  pivot_wider(names_from = "SD", values_from = z) %>% 
  mutate(d = sam - dif) %>% 
  pivot_wider(Subject, names_from = c(Congruency, Alignment), values_from = d) %>% 
  rename(isolated = iso_iso) %>% 
  mutate(fac_subt = con_ali - con_mis, # subtraction
         int_subt = inc_ali - inc_mis, # subtraction
         fac_subt_iso = con_ali - isolated, # subtraction
         int_subt_iso = inc_ali - isolated, # subtraction
         cong_ali_subt = con_ali - inc_ali, # subtraction
         cong_mis_subt = con_mis - inc_mis, # subtraction
         ccfe_subt = cong_ali_subt - cong_mis_subt) %>%  # subtraction
  cal_reg(con_ali ~ con_mis, fac_regr) %>% # regression
  cal_reg(inc_ali ~ inc_mis, int_regr) %>% # regression
  cal_reg(con_ali ~ isolated, fac_regr_iso) %>% # regression
  cal_reg(inc_ali ~ isolated, int_regr_iso) %>% # regression
  cal_reg(con_ali ~ inc_ali, cong_ali_regr) %>% # regression
  cal_reg(con_mis ~ inc_mis, cong_mis_regr) %>% # regression
  cal_reg(cong_ali_subt ~ cong_mis_subt, ccfe_subt_regr) %>% # regression
  cal_reg(cong_ali_regr ~ cong_mis_regr, ccfe_regr_regr) # regression
  
ccfe_d 
```


```{r}
ccfe_rt <- df_ccf_iso %>% 
  filter(Correct) %>% 
  group_by(Subject, Congruency, Alignment) %>% 
  summarize(logrt = log(mean(RT)),
            .groups = "drop") %>% 
  pivot_wider(Subject, names_from = c(Congruency, Alignment), values_from = logrt) %>% 
  rename(isolated = iso_iso) %>% 
  mutate(fac_subt = con_ali - con_mis, # subtraction
         int_subt = inc_ali - inc_mis, # subtraction
         fac_subt_iso = con_ali - isolated, # subtraction
         int_subt_iso = inc_ali - isolated, # subtraction
         cong_ali_subt = con_ali - inc_ali, # subtraction
         cong_mis_subt = con_mis - inc_mis, # subtraction
         ccfe_subt = cong_ali_subt - cong_mis_subt) %>% # subtraction
  cal_reg(con_ali ~ con_mis, fac_regr) %>% # regression
  cal_reg(inc_ali ~ inc_mis, int_regr) %>% # regression
  cal_reg(con_ali ~ isolated, fac_regr_iso) %>% # regression
  cal_reg(inc_ali ~ isolated, int_regr_iso) %>% # regression
  cal_reg(con_ali ~ inc_ali, cong_ali_regr) %>% # regression
  cal_reg(con_mis ~ inc_mis, cong_mis_regr) %>% # regression
  cal_reg(cong_ali_subt ~ cong_mis_subt, ccfe_subt_regr) %>% # regression [first step is subtraction; second step is regression]
  cal_reg(cong_ali_regr ~ cong_mis_regr, ccfe_regr_regr) # regression

ccfe_rt
```


## Reliability of measurement

`psych::splitHalf(..., check.keys=FALSE)` is used to calculate the Guttman's $\lambda_2$ (although it will report results of various methods). Thus, the data have to be prepared to fit the desired structure:

1. The average performance for each `StimGroup` and each participant (for each dependent variable in each task) will be calculated.
2. Then the data needs to be formatted as following, which will be completed later when calculating the reliability for each condition separately.  
- Each matrix is for one condition (and one dependent variable).  
- Each row of the matrix is for one participant.  
- Each column of the matrix is for one `StimGroup`.

```{r}
# a general (custom) function to calculate the reliability for each condition
rel_each <- function(.data, DV, ...){
  
  out <- 
    .data %>%
    filter(...) %>% # to filter out conditions
    pivot_wider(Subject, values_from = all_of(DV), names_from = StimGroup) %>% 
    select(-Subject) %>%
    data.matrix() %>%
    splitHalf(check.keys=FALSE)
  
  return(out$lambda2) # only output lambda2
}
```

```{r}
# function to calculate the reliability of subtraction scores
rel_sub <- function(re_inte, re_base, raw_inte, raw_base){
  
  # re_inte: the reliability of the condition of interest
  # re_base: the reliability of the baseline condition
  # raw_inte: the raw values for each participant in the condition of interest
  # raw_base: the raw values for each participant in the baseline condition
  
  tmp <- 2*sd(raw_inte)*sd(raw_base)*cor(raw_inte, raw_base)
  
  top <- var(raw_inte) * re_inte + var(raw_base) * re_base - tmp
  bot <- var(raw_inte) + var(raw_base) - tmp
  
  return(top/bot)
}

rel_sub1 <- function(re_inte, re_base, raw_inte, raw_base){
  # used in DeGutis et al (2013), but used more assumptions. [to be removed]
  # re_inte: the reliability of the condition of interest
  # re_base: the reliability of the baseline condition
  # raw_inte: the raw values for each participant in the condition of interest
  # raw_base: the raw values for each participant in the baseline condition
  
  return(((re_inte + re_base)/2 - cor(raw_inte, raw_base))/(1-cor(raw_inte, raw_base)))
}

```

```{r}
# function to calculate the reliability of regression scores
rel_reg <- function(re_inte, re_base, raw_inte, raw_base){
  
  # re_inte: the reliability of the condition of interest
  # re_base: the reliability of the baseline condition
  # raw_inte: the raw values for each participant in the condition of interest
  # raw_base: the raw values for each participant in the baseline condition
  
  tmp1 <- cor(raw_inte, raw_base)^2
  
  top <- re_inte + re_base * tmp1 - 2 * tmp1
  bot <- 1 - tmp1
  
  return(top/bot)
}

```


### Part-whole task

```{r}
# PW
df_pw_rel_acc <- df_pw %>%
  group_by(Subject, PW, StimGroup) %>% 
  summarize(acc = mean(Correct),
            count = n(),
            acc_cor = if_else(acc==1, (2*count-1)/(2*count), acc),
            logit = qlogis(acc_cor),
            .groups = "drop") 

df_pw_rel_rt <- df_pw %>%
  filter(Correct) %>% # only keep correct trials
  group_by(Subject, PW, StimGroup) %>% 
  summarize(logrt = log(mean(RT)),
            .groups = "drop") 
```

#### Reliability of each condition

Accuracy for whole:
```{r}
# accuracy on logit scale
rel_pw_acc_w <- rel_each(df_pw_rel_acc, "acc", PW=="whole")
rel_pw_acc_w
```

Accuracy for part:
```{r}
# accuracy on logit scale
rel_pw_acc_p <- rel_each(df_pw_rel_acc, "logit", PW=="part")
rel_pw_acc_p
```

RT for whole:
```{r}
rel_pw_rt_w <- rel_each(df_pw_rel_rt, "logrt", PW=="whole")
rel_pw_rt_w
```

RT for part:
```{r}
rel_pw_rt_p <- rel_each(df_pw_rel_rt, "logrt", PW=="part")
rel_pw_rt_p
```

#### Reliability of the part-whole effect

Subtraction of accuracy
```{r}
# accuracy on logit scale
rel_sub(rel_pw_acc_w, rel_pw_acc_p, pwe_acc$whole, pwe_acc$part)
```

Regression of accuracy
```{r}
# accuracy on logit scale
rel_reg(rel_pw_acc_w, rel_pw_acc_p, pwe_acc$whole, pwe_acc$part)
```

Subtraction of RT
```{r}
rel_sub(rel_pw_rt_w, rel_pw_rt_p, pwe_rt$whole, pwe_rt$part)
```

Regression of RT
```{r}
rel_reg(rel_pw_rt_w, rel_pw_rt_p, pwe_rt$whole, pwe_rt$part)
```

### Standard composite face task

```{r}  
# SCF
df_scf_rel_acc <- df_scf %>% 
  group_by(Subject, Alignment, StimGroup) %>% 
  summarize(acc = mean(Correct),
            count = n(),
            acc_cor = if_else(acc==1, (2*count-1)/(2*count), acc),
            logit = qlogis(acc_cor),
            .groups = "drop")

df_scf_rel_rt <- df_scf %>% 
  filter(Correct) %>% # only keep correct trials
  group_by(Subject, Alignment, StimGroup) %>% 
  summarize(logrt = log(mean(RT)),
            .groups = "drop")
```

#### Reliability of each condition
Accuracy for aligned:
```{r}
# accuracy on logit scale
rel_scf_acc_a <- rel_each(df_scf_rel_acc, "acc", Alignment=="ali")
rel_scf_acc_a
```

Accuracy for misgned
```{r}
# accuracy on logit scale
rel_scf_acc_m <- rel_each(df_scf_rel_acc, "acc", Alignment=="mis")
rel_scf_acc_m
```

RT for aligned
```{r}
rel_scf_rt_a <- rel_each(df_scf_rel_rt, "logrt", Alignment=="ali")
rel_scf_rt_a
```

RT for misaligned
```{r}
rel_scf_rt_m <- rel_each(df_scf_rel_rt, "logrt", Alignment=="mis")
rel_scf_rt_m
```

#### Reliability of the composite effect

Subtraction of accuracy
```{r}
# accuracy on logit scale
rel_sub(rel_scf_acc_a, rel_scf_acc_m, scfe_acc$ali, scfe_acc$mis)
```

Regression of accuracy
```{r}
# accuracy on logit scale
rel_reg(rel_scf_acc_a, rel_scf_acc_m, scfe_acc$ali, scfe_acc$mis)
```

Subtraction of RT
```{r}
rel_sub(rel_scf_rt_a, rel_scf_rt_m, scfe_rt$ali, scfe_rt$mis)
```

Regression of RT
```{r}
rel_reg(rel_scf_rt_a, rel_scf_rt_m, scfe_rt$ali, scfe_rt$mis)
```

### Complete composite face task

```{r}
# CCF
df_ccf_rel_d <- df_ccf_iso %>% # need to include the isolated condition
  group_by(Subject, StimGroup, Congruency, Alignment, SD) %>% 
  summarize(count = n(),
            same_adjust = (sum(isSame)+0.5)/(count+1), # Snodgrass & Corwin (1988)
            .groups = "drop") %>% 
  mutate(z = qnorm(same_adjust)) %>% 
  select(-same_adjust) %>% 
  pivot_wider(names_from = "SD", values_from = z) %>% 
  mutate(d = sam - dif) %>% 
  select(Subject, Congruency, Alignment, StimGroup, d)

df_ccf_rel_rt <- df_ccf_iso %>% 
  filter(Correct) %>% 
  group_by(Subject, StimGroup, Congruency, Alignment) %>% 
  summarize(logrt = log(mean(RT)),
            .groups = "drop")
```


#### Reliability of congruency effects

Congruency in accuracy (aligned)
```{r}
rel_ccf_d_cong_a <- df_ccf_rel_d %>%
  filter(Alignment == "ali") %>% # to filter out conditions
  pivot_wider(c(Subject, StimGroup), values_from = d, names_from = Congruency) %>% 
  mutate(d_cong = con - inc) %>% 
  pivot_wider(Subject, values_from = d_cong, names_from = StimGroup) %>% 
  select(-Subject) %>% 
  data.matrix() %>%
  splitHalf(check.keys=FALSE) 
rel_ccf_d_cong_a <- rel_ccf_d_cong_a$lambda2 # only output lambda2

rel_ccf_d_cong_a
```

Congruency in accuracy (misaligned)
```{r}
rel_ccf_d_cong_m <- df_ccf_rel_d %>%
  filter(Alignment == "mis") %>% # to filter out conditions
  pivot_wider(c(Subject, StimGroup), values_from = d, names_from = Congruency) %>% 
  mutate(d_cong = con - inc) %>% 
  pivot_wider(Subject, values_from = d_cong, names_from = StimGroup) %>% 
  select(-Subject) %>% 
  data.matrix() %>%
  splitHalf(check.keys=FALSE) 
rel_ccf_d_cong_m <- rel_ccf_d_cong_m$lambda2 # only output lambda2

rel_ccf_d_cong_m
```

Congruency in RT (aligned)
```{r}
rel_ccf_rt_cong_a <- df_ccf_rel_rt %>%
  filter(Alignment == "ali") %>% # to filter out conditions
  pivot_wider(c(Subject, StimGroup), values_from = logrt, names_from = Congruency) %>% 
  mutate(rt_cong = con - inc) %>% 
  pivot_wider(Subject, values_from = rt_cong, names_from = StimGroup) %>% 
  select(-Subject) %>% 
  data.matrix() %>%
  splitHalf(check.keys=FALSE) 
rel_ccf_rt_cong_a <- rel_ccf_rt_cong_a$lambda2 # only output lambda2

rel_ccf_rt_cong_a
```

Congruency in RT (misaligned)
```{r}
rel_ccf_rt_cong_m <- df_ccf_rel_rt %>%
  filter(Alignment == "mis") %>% # to filter out conditions
  pivot_wider(c(Subject, StimGroup), values_from = logrt, names_from = Congruency) %>% 
  mutate(rt_cong = con - inc) %>% 
  pivot_wider(Subject, values_from = rt_cong, names_from = StimGroup) %>% 
  select(-Subject) %>% 
  data.matrix() %>%
  splitHalf(check.keys=FALSE) 
rel_ccf_rt_cong_m <- rel_ccf_rt_cong_m$lambda2 # only output lambda2

rel_ccf_rt_cong_m
```

#### Reliability of the composite effect

Subtraction of Congruency (composite effect) in d
```{r}
rel_sub(rel_ccf_d_cong_a, rel_ccf_d_cong_m, ccfe_d$cong_ali_subt, ccfe_d$cong_mis_subt)
```

Regression of Congruency (composite effect) in d
```{r}
rel_reg(rel_ccf_d_cong_a, rel_ccf_d_cong_m, ccfe_d$cong_ali_subt, ccfe_d$cong_mis_subt)
```

Subtraction of RT
```{r}
rel_sub(rel_ccf_rt_cong_a, rel_ccf_rt_cong_m, ccfe_rt$cong_ali_subt, ccfe_rt$cong_mis_subt)
```

Regression of RT
```{r}
rel_reg(rel_scf_rt_a, rel_scf_rt_m, scfe_rt$ali, scfe_rt$mis)
```

#### Reliability of each condition

d for congruent aligned:
```{r}
rel_ccf_d_ca <- rel_each(df_ccf_rel_d, "d", 
                         Congruency=="con", Alignment=="ali")
rel_ccf_d_ca
```

d for incongruent aligned:
```{r}
rel_ccf_d_ia <- rel_each(df_ccf_rel_d, "d", 
                         Congruency=="inc", Alignment=="ali")
rel_ccf_d_ia
```

d for congruent misaligned:
```{r}
rel_ccf_d_cm <- rel_each(df_ccf_rel_d, "d", 
                         Congruency=="con", Alignment=="mis")
rel_ccf_d_cm
```

d for incongruent misaligned:
```{r}
rel_ccf_d_im <- rel_each(df_ccf_rel_d, "d", 
                         Congruency=="inc", Alignment=="mis")
rel_ccf_d_im
```

d for isolated:
```{r}
rel_ccf_d_iso <- rel_each(df_ccf_rel_d, "d", 
                          Congruency=="iso", Alignment=="iso")
rel_ccf_d_iso
```

RT for congruent aligned:
```{r}
rel_ccf_rt_ca <- rel_each(df_ccf_rel_rt, "logrt", 
                          Congruency=="con", Alignment=="ali")
rel_ccf_rt_ca
```

RT for incongruent aligned:
```{r}
rel_ccf_rt_ia <- rel_each(df_ccf_rel_rt, "logrt", 
                          Congruency=="inc", Alignment=="ali")
rel_ccf_rt_ia
```

RT for congruent misaligned:
```{r}
rel_ccf_rt_cm <- rel_each(df_ccf_rel_rt, "logrt", 
                          Congruency=="con", Alignment=="mis")
rel_ccf_rt_cm
```

RT for incongruent misaligned:
```{r}
rel_ccf_rt_im <- rel_each(df_ccf_rel_rt, "logrt", 
                          Congruency=="inc", Alignment=="mis")
rel_ccf_rt_im
```

RT for isolated:
```{r}
rel_ccf_rt_iso <- rel_each(df_ccf_rel_rt, "logrt", 
                           Congruency=="iso", Alignment=="iso")
rel_ccf_rt_iso
```


#### Reliability of facilitation

Subtraction of accuracy (with isolated baselines)
```{r}
rel_sub(rel_ccf_d_ca, rel_ccf_d_iso, ccfe_d$con_ali, ccfe_d$isolated)
```

Regression of accuracy (with isolated baselines)
```{r}
rel_reg(rel_ccf_d_ca, rel_ccf_d_iso, ccfe_d$con_ali, ccfe_d$isolated)
```

Subtraction of RT (with isolated baselines)
```{r}
rel_sub(rel_ccf_rt_ca, rel_ccf_rt_iso, ccfe_rt$con_ali, ccfe_rt$isolated)
```

Regression of RT (with isolated baselines)
```{r}
rel_reg(rel_ccf_rt_ca, rel_ccf_rt_iso, ccfe_rt$con_ali, ccfe_rt$isolated)
```

Subtraction of accuracy (with misaligned baselines)
```{r}
rel_sub(rel_ccf_d_ca, rel_ccf_d_cm, ccfe_d$con_ali, ccfe_d$con_mis)
```

Regression of accuracy (with misaligned baselines)
```{r}
rel_reg(rel_ccf_d_ca, rel_ccf_d_cm, ccfe_d$con_ali, ccfe_d$con_mis)
```

Subtraction of RT (with misaligned baselines)
```{r}
rel_sub(rel_ccf_rt_ca, rel_ccf_rt_cm, ccfe_rt$con_ali, ccfe_rt$con_mis)
```

Regression of RT (with misaligned baselines)
```{r}
rel_reg(rel_ccf_rt_ca, rel_ccf_rt_cm, ccfe_rt$con_ali, ccfe_rt$con_mis)
```


#### Reliability of interference

Subtraction of accuracy (with isolated baselines)
```{r}
rel_sub(rel_ccf_d_ia, rel_ccf_d_iso, ccfe_d$inc_ali, ccfe_d$isolated)
```

Regression of accuracy (with isolated baselines)
```{r}
rel_reg(rel_ccf_d_ia, rel_ccf_d_iso, ccfe_d$inc_ali, ccfe_d$isolated)
```

Subtraction of RT (with isolated baselines)
```{r}
rel_sub(rel_ccf_rt_ia, rel_ccf_rt_iso, ccfe_rt$inc_ali, ccfe_rt$isolated)
```

Regression of RT (with isolated baselines)
```{r}
rel_reg(rel_ccf_rt_ia, rel_ccf_rt_iso, ccfe_rt$inc_ali, ccfe_rt$isolated)
```

Subtraction of accuracy (with misaligned baselines)
```{r}
rel_sub(rel_ccf_d_ia, rel_ccf_d_im, ccfe_d$inc_ali, ccfe_d$inc_mis)
```

Regression of accuracy (with misaligned baselines)
```{r}
rel_reg(rel_ccf_d_ia, rel_ccf_d_im, ccfe_d$inc_ali, ccfe_d$inc_mis)
```

Subtraction of RT (with misaligned baselines)
```{r}
rel_sub(rel_ccf_rt_ia, rel_ccf_rt_im, ccfe_rt$inc_ali, ccfe_rt$inc_mis)
```

Regression of RT (with misaligned baselines)
```{r}
rel_reg(rel_ccf_rt_ia, rel_ccf_rt_im, ccfe_rt$inc_ali, ccfe_rt$inc_mis)
```


## Correlations among holistic processing effects

```{r}
# custom function to print the correlation results via library(psych)
psych_cor <- function(.data, ...) {
  
  # .data: data frame only includes columns for correlation (no subject code column)
  # Usage: psych_cor(hpe_acc_subt)
  
  # run correlations
  cor_tmp <- corr.test(.data, ...)
  
  cor_tmp$ci %>% 
    mutate(N = cor_tmp$n,
           p.adj = cor_tmp$p.adj,
           adjust = cor_tmp$adjust) %>% 
    bind_cols(cor_tmp$ci.adj %>% mutate(r=1) %>% select(-r)) %>% 
    return()
}
```

### Equivalence tests

```{r}
# equivalence interval
delta_null_hp <- .15  # the equivalent interval will be [-delta_null_hp, delta_null_hp]

df_equi_hp <- tibble(
  Scenarios = paste("Scenario", 1:6),
  CI_low = c(delta_null_hp-.05, -delta_null_hp-.08, -delta_null_hp+.02, -.04, -delta_null_hp-.04, -delta_null_hp-.02),
  CI_upp = CI_low + c(rep(0.2, 5), 0.34)
) %>% 
  mutate(Scenarios = factor(Scenarios),
         Scenarios = factor(Scenarios, levels = rev(levels(Scenarios))))

plot_equi_hp <- ggplot(df_equi_hp, aes(xmin = CI_low, xmax = CI_upp, y = Scenarios)) +
  geom_errorbarh(height = .4, color = c("#D55E00", "#D55E00", "#56B4E9",
                                        "gray30", "gray30", "gray30"), size = 1) +  # , "gray30"
  geom_vline(xintercept = 0, linetype = "longdash") +
  geom_vline(xintercept = c(-delta_null_hp,delta_null_hp), linetype = "dashed", color = "gray30") +
  scale_x_continuous(limits = c(-.3, .3), breaks = c(-delta_null_hp, 0, delta_null_hp)) +
  xlab("Correlation coefficient") +
  papaja::theme_apa() +
  NULL

# ggsave("equivalence_test_hp.png", plot_equi_hp, width = 8, height = 5)

plot_equi_hp
```


### Subtraction

```{r}
hpe_acc_subt <- pwe_acc %>% 
  inner_join(scfe_acc, by="Subject") %>% 
  inner_join(ccfe_d, by="Subject") %>% 
  transmute(pwe_subt, scfe_subt=-scfe_subt, ccfe_subt) 

hpe_rt_subt <- pwe_rt %>% 
  inner_join(scfe_rt, by="Subject") %>% 
  inner_join(ccfe_rt, by="Subject") %>% 
  transmute(pwe_subt, scfe_subt=-scfe_subt, ccfe_subt)
```

```{r}
corPlot(hpe_acc_subt)
```

```{r}
psych_cor(hpe_acc_subt)
```

```{r}
corPlot(hpe_rt_subt)
```

```{r}
psych_cor(hpe_rt_subt)
```

### Regression

```{r}
hpe_acc_regr <- pwe_acc %>% 
  inner_join(scfe_acc, by="Subject") %>% 
  inner_join(ccfe_d, by="Subject") %>% 
  transmute(pwe_regr, scfe_regr=-scfe_regr, ccfe_subt_regr)

hpe_rt_regr <- pwe_rt %>% 
  inner_join(scfe_rt, by="Subject") %>% 
  inner_join(ccfe_rt, by="Subject") %>% 
  transmute(pwe_regr, scfe_regr=-scfe_regr, ccfe_subt_regr)
```


```{r}
corPlot(hpe_acc_regr)
```

```{r}
psych_cor(hpe_acc_regr)
```

```{r}
corPlot(hpe_rt_regr)
```

```{r}
psych_cor(hpe_rt_regr)
```


## Correlations for facilitation and interference

```{r}
# equivalence interval
delta_null <- .15  # the equivalent interval will be [-delta_null, delta_null]

df_equi <- tibble(
  Scenarios = paste("Scenario", 1:7),
  CI_low = c(delta_null+.02, delta_null-.1, .03, -delta_null+.05, -.14, -delta_null-.03, -.05),
  CI_upp = CI_low + c(.2, .2, 0.1, .2, 0.1, .3, .3)
) %>% 
  mutate(Scenarios = factor(Scenarios),
         Scenarios = factor(Scenarios, levels = rev(levels(Scenarios))))

plot_equi <- ggplot(df_equi, aes(xmin = CI_low, xmax = CI_upp, y = Scenarios)) +
  geom_errorbarh(height = .4, color = c("#D55E00", "#D55E00", "#D55E00",
                                        "#56B4E9", "#56B4E9", "#56B4E9", "gray30"), size = 1) + 
  geom_vline(xintercept = 0, linetype = "longdash") +
  geom_vline(xintercept = delta_null, linetype = "dashed", color = "gray30") +
  scale_x_continuous(limits = c(-.25, .4), breaks = c(-delta_null, 0, delta_null)) +
  xlab("Correlation coefficient") +
  papaja::theme_apa() +
  NULL

# ggsave("equivalence_test.png", plot_equi, width = 8, height = 5)

plot_equi
```


### PW and Facilitation in CCF

#### Subtraction

```{r}
psych_cor(pwe_acc$pwe_subt, ccfe_d$fac_subt)
```


```{r}
psych_cor(pwe_acc$pwe_subt, ccfe_d$fac_subt_iso)
```

```{r}
psych_cor(pwe_rt$pwe_subt, ccfe_rt$fac_subt)
```


```{r}
psych_cor(pwe_rt$pwe_subt, ccfe_rt$fac_subt_iso)
```

#### Regressions

```{r}
psych_cor(pwe_acc$pwe_regr, ccfe_d$fac_regr)
```


```{r}
psych_cor(pwe_acc$pwe_regr, ccfe_d$fac_regr_iso)
```

```{r}
psych_cor(pwe_rt$pwe_regr, ccfe_rt$fac_regr)
```


```{r}
psych_cor(pwe_rt$pwe_regr, ccfe_rt$fac_regr_iso)
```

### SCF and Interference in CCF

#### Subtraction

```{r}
psych_cor(scfe_acc$scfe_subt, ccfe_d$int_subt)
```

```{r}
psych_cor(scfe_acc$scfe_subt, ccfe_d$int_subt_iso)
```

```{r}
psych_cor(scfe_rt$scfe_subt, ccfe_rt$int_subt)
```

```{r}
psych_cor(scfe_rt$scfe_subt, ccfe_rt$int_subt_iso)
```

#### Regressions

```{r}
psych_cor(scfe_acc$scfe_regr, ccfe_d$int_regr)
```

```{r}
psych_cor(scfe_acc$scfe_regr, ccfe_d$int_regr_iso)
```

```{r}
psych_cor(scfe_rt$scfe_regr, ccfe_rt$int_regr)
```

```{r}
psych_cor(scfe_rt$scfe_regr, ccfe_rt$int_regr_iso)
```

### Pairwise correlations

#### Performance

```{r fig.width=8, fig.asp=1}
pwe_acc %>% 
  inner_join(scfe_acc, by="Subject") %>% 
  inner_join(ccfe_d, by="Subject") %>% 
  select(-Subject, -contains("regr")) %>% 
  cor.plot()
```

```{r fig.width=8, fig.asp=1}
pwe_acc %>% 
  inner_join(scfe_acc, by="Subject") %>% 
  inner_join(ccfe_d, by="Subject") %>% 
  select(-Subject, -contains("subt"), ccfe_subt_regr) %>% 
  cor.plot()
```

#### Response times

```{r fig.width=6, fig.asp=1}
pwe_rt %>% 
  left_join(scfe_rt, by="Subject") %>% 
  left_join(ccfe_rt, by="Subject") %>% 
  select(-Subject, -contains("regr")) %>% 
  cor.plot()
```

```{r fig.width=8, fig.asp=1}
pwe_rt %>% 
  left_join(scfe_rt, by="Subject") %>% 
  left_join(ccfe_rt, by="Subject") %>% 
  select(-Subject, -contains("subt"), ccfe_subt_regr) %>% 
  cor.plot()
```

# Session information {.unlisted .unnumbered}
```{r}
sessionInfo()
```
